{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pyspark python3 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/ml/Desktop/spam/trec07p/data'\n",
    "LABELS_FILE = '/home/ml/Desktop/spam/trec07p/full/index'\n",
    "TRAINING_SET_RATIO = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "# Read the labels.\n",
    "with open(LABELS_FILE) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        label, key = line.split()\n",
    "        labels[key.split('/')[-1]] = 1 if label.lower() == 'ham' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_email_text(path):\n",
    "    # Load a single email from an input file.\n",
    "    with open(path) as f:\n",
    "        # msg = email.message_from_file(f)\n",
    "        # with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "        text = f.read()\n",
    "        msg = email.message_from_string(text)\n",
    "    if not msg:\n",
    "        return ''\n",
    "\n",
    "    # Read the email subject.\n",
    "    subject = msg['Subject']\n",
    "    if subject:\n",
    "        subject = subject\n",
    "    else:\n",
    "        subject = ''\n",
    "\n",
    "    # Read the email body.\n",
    "    body = None\n",
    "    try:\n",
    "        body = ' '.join(m for m in flatten_to_string(msg.get_payload()) if type(m) == str)\n",
    "    except: pass\n",
    "    if body:\n",
    "        body = body\n",
    "    else:\n",
    "        body = ''\n",
    "\n",
    "    return subject + '\\n' + body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_to_string(parts):\n",
    "    ret = []\n",
    "    if type(parts) == str:\n",
    "        ret.append(parts)\n",
    "    elif type(parts) == list:\n",
    "        for part in parts:\n",
    "            ret.extend(flatten_to_string(part))\n",
    "    elif parts.get_content_type() == 'text/plain':\n",
    "        ret.append(parts.get_payload())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_email_files():\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(labels)):\n",
    "        filename = 'inmail.' + str(i+1)\n",
    "        email_str = extract_email_text(os.path.join(DATA_DIR, filename))\n",
    "        X.append(email_str)\n",
    "        y.append(float(labels[filename]))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = read_email_files()\n",
    "\n",
    "schema = StructType([\n",
    "            StructField('id', IntegerType(), nullable=False),\n",
    "            StructField('email', StringType(), nullable=False),\n",
    "            StructField('label', DoubleType(), nullable=False)])\n",
    "\n",
    "df = spark.createDataFrame(zip(range(len(y)), X, y), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "root\n",
    " |-- id: integer (nullable = false)\n",
    " |-- email: string (nullable = false)\n",
    " |-- label: double (nullable = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([TRAINING_SET_RATIO, 1-TRAINING_SET_RATIO], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "vectorizer = CountVectorizer()\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, vectorizer, rfc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paramMap = {\n",
    "    tokenizer.inputCol: 'email',\n",
    "    tokenizer.outputCol: 'tokens',\n",
    "\n",
    "    vectorizer.inputCol: 'tokens',\n",
    "    vectorizer.outputCol: 'vectors',\n",
    "\n",
    "    rfc.featuresCol: 'vectors',\n",
    "    rfc.labelCol: 'label',\n",
    "    rfc.numTrees: 500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(train, params=paramMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction')\n",
    "pr_score = evaluator.evaluate(prediction, {evaluator.metricName: 'areaUnderPR'})\n",
    "roc_score = evaluator.evaluate(prediction, {evaluator.metricName: 'areaUnderROC'})\n",
    "\n",
    "print(\"Area under ROC curve score: {:.3f}\".format(roc_score))\n",
    "print(\"Area under precision/recall curve score: {:.3f}\".format(pr_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under ROC curve score: 0.971\n",
    "Area under precision/recall curve score: 0.958\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
